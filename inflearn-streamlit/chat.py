import streamlit as st    
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import RetrievalQA
from langchain import hub
from langchain_upstage import ChatUpstage
from dotenv import load_dotenv
from langchain_upstage import UpstageEmbeddings
from langchain_pinecone import PineconeVectorStore

load_dotenv()

st.set_page_config(page_title="ì†Œë“ì„¸ ì±—ë´‡", page_icon="ğŸ’°")

st.title("ğŸ’° ì†Œë“ì„¸ ì±—ë´‡")
st.caption("ì†Œë“ì„¸ì— ê´€ë ¨ëœ ëª¨ë“  ê²ƒì„ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤!")

if 'message_list' not in st.session_state:
    st.session_state.message_list = []

for message in st.session_state.message_list:
    with st.chat_message(message["role"]):
        st.write(message["content"])

def get_ai_message(user_message):
    embedding = UpstageEmbeddings(model="solar-embedding-1-large")
    index_name = 'tax-table-index'
    database = PineconeVectorStore.from_existing_index(embedding=embedding, index_name=index_name)

    llm = ChatUpstage()
    prompt = hub.pull("rlm/rag-prompt")
    retriever=database.as_retriever()

    qa_chain = RetrievalQA.from_chain_type(
        llm,
        retriever=retriever,
        chain_type_kwargs={"prompt": prompt}
    )

    dictionary = ["ì‚¬ëŒì„ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„ì€ ê±°ì£¼ìë¡œ ì •ì˜í•œë‹¤.", "ê¸ˆì•¡ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì´ë©´ ì§ˆë¬¸ì˜ ëì— *ì°¸ê³ : ì œëŒ€ë¡œ ëœ ì—°ì‚°ì´ í•„ìš”í•©ë‹ˆë‹¤.*ë¥¼ ì¶”ê°€í•œë‹¤."]

    prompt = ChatPromptTemplate.from_template("""
        1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³´ê³ , ìš°ë¦¬ì˜ ì‚¬ì „ì„ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•´ì£¼ì„¸ìš”.
        2. ë§Œì•½, ë³€ê²½í•  í•„ìš”ê°€ ì—†ë‹¤ê³  íŒë‹¨ëœë‹¤ë©´ ë³€ê²½í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
        ì‚¬ì „: {dictionary}
                                            
        ì§ˆë¬¸: {question}
    """)

    dictionary_chain = prompt | llm | StrOutputParser()
    tax_chain = {"query": dictionary_chain} | qa_chain
    ai_response = tax_chain.invoke({"dictionary": dictionary, "question": user_message})
    return ai_response['result']

if user_question := st.chat_input(placeholder="ì†Œë“ì„¸ì— ê´€ë ¨ëœ ê¶ê¸ˆí•œ ë‚´ìš©ë“¤ì„ ë§ì”€í•´ì£¼ì„¸ìš”!"):
    with st.chat_message("user"):
        st.write(user_question)
    st.session_state.message_list.append({"role":"user", "content": user_question})

    with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤."):
        ai_message = get_ai_message(user_question)
        with st.chat_message("ai"):
            st.write(ai_message)
        st.session_state.message_list.append({"role":"ai", "content": ai_message})

    